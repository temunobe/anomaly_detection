{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e17f8eaf",
   "metadata": {},
   "source": [
    "# Structure\n",
    "1. Dependecies\n",
    "2. Model\n",
    "3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa93fc96",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb92e593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, torch, requests, logging, json, random, wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from datasets import load_dataset, Dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "#from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import RobertaTokenizerFast, TrainingArguments, Trainer, DataCollatorWithPadding, RobertaForSequenceClassification\n",
    "from config import config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddddab33",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b59eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ae870a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce16905",
   "metadata": {},
   "source": [
    "# Load The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fad18fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = config['data_dir'] \n",
    "MODEL_NAME = \"roberta-base\"\n",
    "OUTPUT_DIR = config['output']\n",
    "LOGGING_DIR = config['logs'] \n",
    "WANDB_API_KEY = config['wb_api_key']\n",
    "WANDB_PROJECT = 'llm-anomaly-detection'\n",
    "WANDB_ENTITY = 'bsindala-university-of-alabama-at-birmigham'\n",
    "NUM_EPOCHS = 3#10 #3\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 1e-5\n",
    "MAX_SEQ_LENGTH = 256\n",
    "CLASS_CONFIG = 2 # Choose 19, 6, or 2 based on your experiment\n",
    "RANDOM_STATE = 42\n",
    "SAMPLE_FRAC=0.2\n",
    "SAVE_EVAL_RESULTS = True\n",
    "# SAMPLE_SIZE = None # For testing, None=Full Dataset\n",
    "# LABEL_COLUMN = 'Attack_Type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "171a43ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 19 class mapping\n",
    "ATTACK_CATEGORIES_19 = {\n",
    "    'ARP_Spoofing': 'Spoofing',\n",
    "    'MQTT-DDoS-Connect_Flood': 'MQTT-DDoS-Connect_Flood',\n",
    "    'MQTT-DDoS-Publish_Flood': 'MQTT-DDoS-Publish_Flood',\n",
    "    'MQTT-DoS-Connect_Flood': 'MQTT-DoS-Connect_Flood',\n",
    "    'MQTT-DoS-Publish_Flood': 'MQTT-DoS-Publish_Flood',\n",
    "    'MQTT-Malformed_Data': 'MQTT-Malformed_Data',\n",
    "    'Recon-OS_Scan': 'Recon-OS_Scan',\n",
    "    'Recon-Ping_Sweep': 'Recon-Ping_Sweep',\n",
    "    'Recon-Port_Scan': 'Recon-Port_Scan',\n",
    "    'Recon-VulScan': 'Recon-VulScan',\n",
    "    'TCP_IP-DDoS-ICMP': 'DDoS-ICMP',\n",
    "    'TCP_IP-DDoS-SYN': 'DDoS-SYN',\n",
    "    'TCP_IP-DDoS-TCP': 'DDoS-TCP',\n",
    "    'TCP_IP-DDoS-UDP': 'DDoS-UDP',\n",
    "    'TCP_IP-DoS-ICMP': 'DoS-ICMP',\n",
    "    'TCP_IP-DoS-SYN': 'DoS-SYN',\n",
    "    'TCP_IP-DoS-TCP': 'DoS-TCP',\n",
    "    'TCP_IP-DoS-UDP': 'DoS-UDP',\n",
    "    'Benign': 'Benign'\n",
    "}\n",
    "\n",
    "# 6 Class mapping\n",
    "ATTACK_CATEGORIES_6 = { \n",
    "    'Spoofing': 'Spoofing',\n",
    "    'MQTT-DDoS-Connect_Flood': 'MQTT',\n",
    "    'MQTT-DDoS-Publish_Flood': 'MQTT',\n",
    "    'MQTT-DoS-Connect_Flood': 'MQTT',\n",
    "    'MQTT-DoS-Publish_Flood': 'MQTT',\n",
    "    'MQTT-Malformed_Data': 'MQTT',\n",
    "    'Recon-OS_Scan': 'Recon',\n",
    "    'Recon-Ping_Sweep': 'Recon',\n",
    "    'Recon-Port_Scan': 'Recon',\n",
    "    'Recon-VulScan': 'Recon',\n",
    "    'DDoS-ICMP': 'DDoS',\n",
    "    'DDoS-SYN': 'DDoS',\n",
    "    'DDoS-TCP': 'DDoS',\n",
    "    'DDoS-UDP': 'DDoS',\n",
    "    'DoS-ICMP': 'DoS',\n",
    "    'DoS-SYN': 'DoS',\n",
    "    'DoS-TCP': 'DoS',\n",
    "    'DoS-UDP': 'DoS',\n",
    "    'Benign': 'Benign'\n",
    "}\n",
    "\n",
    "# 2 class mapping\n",
    "ATTACK_CATEGORIES_2 = { #\n",
    "    'ARP_Spoofing': 'attack',\n",
    "    'MQTT-DDoS-Connect_Flood': 'attack',\n",
    "    'MQTT-DDoS-Publish_Flood': 'attack',\n",
    "    'MQTT-DoS-Connect_Flood': 'attack',\n",
    "    'MQTT-DoS-Publish_Flood': 'attack',\n",
    "    'MQTT-Malformed_Data': 'attack',\n",
    "    'Recon-OS_Scan': 'attack',\n",
    "    'Recon-Ping_Sweep': 'attack',\n",
    "    'Recon-Port_Scan': 'attack',\n",
    "    'Recon-VulScan': 'attack',\n",
    "    'TCP_IP-DDoS-ICMP': 'attack',\n",
    "    'TCP_IP-DDoS-SYN': 'attack',\n",
    "    'TCP_IP-DDoS-TCP': 'attack',\n",
    "    'TCP_IP-DDoS-UDP': 'attack',\n",
    "    'TCP_IP-DoS-ICMP': 'attack',\n",
    "    'TCP_IP-DoS-SYN': 'attack',\n",
    "    'TCP_IP-DoS-TCP': 'attack',\n",
    "    'TCP_IP-DoS-UDP': 'attack',\n",
    "    'Benign': 'Benign'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257edaf0",
   "metadata": {},
   "source": [
    "# Load Data Together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6932cc48",
   "metadata": {},
   "source": [
    "## Attack Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0faf2f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attack_category(label, class_config):\n",
    "    if class_config == 2:\n",
    "        categories = ATTACK_CATEGORIES_2\n",
    "    elif class_config == 6:\n",
    "        categories = ATTACK_CATEGORIES_6\n",
    "    elif class_config == 19:\n",
    "        categories = ATTACK_CATEGORIES_19\n",
    "        \n",
    "    for key in categories:\n",
    "        if key in label:\n",
    "            return categories[key]\n",
    "    logger.warning(f\"Could not map label: {label} with class_config: {class_config}. Returning 'Unknown'\")\n",
    "    return 'Unknown Category'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a3e0a9",
   "metadata": {},
   "source": [
    "## Textualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1724942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def textualize_flow(row, feature_names, sep_token='</s>'):\n",
    "    text_parts = []\n",
    "    for feature_name in feature_names:\n",
    "        if feature_name in row:\n",
    "            value = row[feature_name]\n",
    "            clean_feature_name = feature_name.replace('_',' ').replace('-',' ').replace('/',' ')\n",
    "            \n",
    "        if pd.isnull(value):\n",
    "            value = 'missing'\n",
    "        elif isinstance(value, float):\n",
    "            value = f'{value:.2f}' if abs(value) >= 0.01 else f'{value:.4f}'\n",
    "        elif isinstance(value, int):\n",
    "            value = str(value)\n",
    "        else:\n",
    "            value = str(value)\n",
    "            \n",
    "#         if 'bytes' in clean_feature_name.lower():\n",
    "#             text_parts.append(f'The {clean_feature_name} is {value} bytes')\n",
    "#         elif 'time' in clean_feature_name.lower() or 'duration' in clean_feature_name.lower():\n",
    "#             text_parts.append(f'The {clean_feature_name} is {value} seconds')\n",
    "#         else:\n",
    "#             text_parts.append(f'The {clean_feature_name} is {value}')\n",
    "        text_parts.append(f\"{clean_feature_name}:{value}\")\n",
    "    return f' {sep_token}'.join(text_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28aa623f",
   "metadata": {},
   "source": [
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "806122e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare(data_dir, class_config, tokenizer, max_seq_len=256, test_size_for_val=0.2, random_state=42, sample_frac=0.2):\n",
    "    logger.info(f\"Loading and preparing datasets for {class_config}-class configuration...\")\n",
    "\n",
    "    train_path = os.path.join(data_dir, \"train\")\n",
    "    test_path = os.path.join(data_dir, \"test\")\n",
    "\n",
    "    if not os.path.exists(train_path) or not os.path.isdir(train_path):\n",
    "        raise FileNotFoundError(f\"Training directory not found or is not a directory: {train_path}.\")\n",
    "    if not os.path.exists(test_path) or not os.path.isdir(test_path):\n",
    "        raise FileNotFoundError(f\"Testing directory not found or is not a directory: {test_path}.\")\n",
    "\n",
    "    train_files = [os.path.join(train_path, f) for f in os.listdir(train_path) if f.endswith('.csv')]\n",
    "    test_files = [os.path.join(test_path, f) for f in os.listdir(test_path) if f.endswith('.csv')]\n",
    "\n",
    "    if not train_files or not test_files:\n",
    "        raise FileNotFoundError(\"No CSV files found in training or test directories.\")\n",
    "\n",
    "    logger.info(\"Loading datasets with streaming...\")\n",
    "\n",
    "    # Define default features\n",
    "    selected_features = [\n",
    "        'Src IP', 'Dst IP', 'Protocol', 'Flow Duration', 'Pkt Len Mean',\n",
    "        'Fwd Pkt Len Mean', 'Bwd Pkt Len Mean', 'Flow Pkts/s', 'Flow IAT Mean',\n",
    "        'Fwd IAT Tot', 'Bwd IAT Tot', 'Fwd PSH Flags', 'BWd PSH Flags'\n",
    "    ]\n",
    "\n",
    "    def process_batch(batch, feature_cols):\n",
    "        \"\"\"Process a batch of data for textualization and labeling\"\"\"\n",
    "        if isinstance(batch, dict):\n",
    "            batch = [batch]\n",
    "\n",
    "        df = pd.DataFrame(batch)\n",
    "        df = df.fillna(df.mean(numeric_only=True))\n",
    "        df['Attack_Type'] = df['filename'].apply(lambda x: get_attack_category(x, class_config))\n",
    "        df = df[df['Attack_Type'] != 'Unknown Category'].copy()\n",
    "        if df.empty:\n",
    "            logger.warning('Empty batch after filtering unknown categories.')\n",
    "            return None\n",
    "        feature_cols = [col for col in df.columns if col not in ['filename', 'Attack_Type']]\n",
    "        df['text'] = df.apply(lambda row: textualize_flow(row, feature_cols), axis=1)\n",
    "        return df[['text', 'Attack_Type']]\n",
    "\n",
    "    train_texts, train_labels = [], []\n",
    "    test_texts, test_labels = [], []\n",
    "\n",
    "    logger.info('Processing train data...')\n",
    "    for file_path in train_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        train_dataset = load_dataset('csv', data_files={'train': file_path}, streaming=True)['train']\n",
    "        for example in train_dataset:\n",
    "            if isinstance(example, dict):\n",
    "                example['filename'] = filename\n",
    "                df_batch = process_batch(example, selected_features)\n",
    "                if df_batch is not None:\n",
    "                    train_texts.extend(df_batch['text'].tolist())\n",
    "                    train_labels.extend(df_batch['Attack_Type'].tolist())\n",
    "            else:\n",
    "                logger.warning(f'Unexcepted data format in {filename}: {type(example)}')\n",
    "\n",
    "    logger.info('Processing test data...')\n",
    "    for file_path in test_files:\n",
    "        filename = os.path.basename(file_path)\n",
    "        test_dataset = load_dataset('csv', data_files={'test': file_path}, streaming=True)['test']\n",
    "        for example in test_dataset:\n",
    "            if isinstance(example, dict):\n",
    "                example['filename'] = filename\n",
    "                df_batch = process_batch(example, selected_features)\n",
    "                if df_batch is not None:\n",
    "                    test_texts.extend(df_batch['text'].tolist())\n",
    "                    test_labels.extend(df_batch['Attack_Type'].tolist())\n",
    "            else:\n",
    "                logger.warning(f'Unexcepted data format in {filename}: {type(example)}')\n",
    "\n",
    "    if sample_frac < 1.0:\n",
    "        logger.info(f'Subsampling {sample_frac*100:.1f}% of training data...')\n",
    "        indices = np.random.choice(len(train_texts), size=int(len(train_texts) * sample_frac), replace=False)\n",
    "        train_texts = [train_texts[i] for i in indices]\n",
    "        train_labels = [train_labels[i] for i in indices]\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    all_labels = list(set(train_labels + test_labels))\n",
    "    label_encoder.fit(all_labels)\n",
    "    train_labels = label_encoder.transform(train_labels)\n",
    "    test_labels = label_encoder.transform(test_labels)\n",
    "\n",
    "    num_classes = len(label_encoder.classes_)\n",
    "    logger.info(f\"Number of classes: {num_classes}, classes: {list(label_encoder.classes_)}\")\n",
    "\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "        train_texts,\n",
    "        train_labels,\n",
    "        test_size=test_size_for_val,\n",
    "        random_state=random_state,\n",
    "        stratify=train_labels\n",
    "    )\n",
    "\n",
    "    logger.info(f'Training samples: {len(train_texts)}, Validation samples: {len(val_texts)}, Test samples: {len(test_texts)}')\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=max_seq_len)\n",
    "\n",
    "    train_ds = Dataset.from_dict({'text': train_texts, 'label': train_labels}).map(tokenize_function, batched=True, batch_size=1000)\n",
    "    val_ds = Dataset.from_dict({'text': val_texts, 'label': val_labels}).map(tokenize_function, batched=True, batch_size=1000)\n",
    "    test_ds = Dataset.from_dict({'text': test_texts, 'label': test_labels}).map(tokenize_function, batched=True, batch_size=1000)\n",
    "\n",
    "    try:\n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(train_labels), y=train_labels)\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "        logger.info(f\"Class weights: {class_weights}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to compute class weights: {e}\")\n",
    "        class_weights = {i: 1.0 for i in range(num_classes)}\n",
    "        logger.info(f\"Using equal class weights as fallback: {class_weights}\")\n",
    "\n",
    "    return train_ds, val_ds, test_ds, label_encoder, class_weights, selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6ff3fa",
   "metadata": {},
   "source": [
    "# RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dec73527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'roberta-base'\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(model_name)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "def init_roberta_model(model_name, num_labels=2, id2label=None, label2id=None, dropout=0.1, use_lora=True, lora_r=16):\n",
    "    \"\"\"\n",
    "    Initialize RoBERTa model for sequence classification\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Name or path of the pretrained RoBERTa model (default: 'roberta-base')\n",
    "        num_labels (int): Number of output labels (e.g., 2 for binary anomaly detection)\n",
    "        id2label (dict, optional): Mapping from label IDs to label names \n",
    "        label2id (dict, optional): Mapping from label names to label IDs\n",
    "        dropout (float, optional): Custom dropout rate for classifier head (default: 0.1)\n",
    "        use_lora (bool): Whether to apply LoRA for parameter-efficient fine-tuning (default: True)\n",
    "        lora_r (int): LoRA rank parameter (default: 16)\n",
    "    Returns: \n",
    "        RobertaForSequenceClassification: Initialized model, optionally with LoRA\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info(f\"Initializing RoBERTa model: {model_name} with {num_labels} labels, LoRA={use_lora}\")\n",
    "    try:\n",
    "        model = RobertaForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_labels,\n",
    "            id2label=id2label,\n",
    "            label2id=label2id,\n",
    "            hidden_dropout_prob=dropout if dropout is not None else 0.1,\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "        )\n",
    "        \n",
    "        model.gradient_checkpointing_enable()\n",
    "        \n",
    "        if use_lora:\n",
    "            lora_config = LoraConfig(\n",
    "                r=lora_r,\n",
    "                lora_alpha=32,\n",
    "                target_modules=['query', 'value'],\n",
    "                lora_dropout=0.05,\n",
    "                bias='none',\n",
    "                task_type='SEQ_CLS'\n",
    "            )\n",
    "            model = get_peft_model(model, lora_config)\n",
    "            \n",
    "            # Logging trainable parameters\n",
    "            total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "            logger.info(f'Applied LoRA with rank={lora_r}, trainable params: {total_params}')\n",
    "            if wandb.run is not None:\n",
    "                wandb.log({\"trainable_params\": total_params, \"lora_rank\": lora_r})\n",
    "        \n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model.to(device)\n",
    "        logger.info(f'Model moved to device: {device}')\n",
    "        if wandb.run is not None:\n",
    "            wandb.log({\"device\": str(device)})\n",
    "\n",
    "        return model\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f'Failed to initialize model: {e}')\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bcc8e7",
   "metadata": {},
   "source": [
    "### Custom Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "994c6969",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainerWithWeightedLoss(Trainer):\n",
    "    \"\"\"\n",
    "    Custom Trainer to apply class weights to the loss function.\n",
    "    \n",
    "    Args: \n",
    "        class_weights (torch.Tensor): Tensor of class weights for imbalanced classification.\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        if class_weights is not None:\n",
    "            weights = torch.tensor(list(class_weights.values()), dtype=torch.float32)\n",
    "            weights = weights / weights.sum() * len(weights)\n",
    "            self.class_weights = weights.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "            if wandb.run is None:\n",
    "                wandb.log({\"class_weights\": {i: w.item() for i, w in enumerate(self.class_weights)}})\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "        logger.info(f'Class weights initialized: {self.class_weights}')\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \"\"\"\n",
    "        Compute the weighted cross-entropy loss\n",
    "        \n",
    "        Args:\n",
    "            model: The model being trained\n",
    "            inputs (dict): Input batch including 'labels'\n",
    "            return_output (bool): Whether to return model outputs \n",
    "            \n",
    "        Returns:\n",
    "            loss or (loss, outputs)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            labels = inputs.pop('labels')\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            loss_fnct = torch.nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "            loss = loss_fnct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "            if wandb.run is not None:\n",
    "                wandb.log({\"batch_loss\": loss.item()})\n",
    "    \n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "        except Exception as e:\n",
    "            logger.error(f'Error computing loss: {e}')\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bbb2b6",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32ae79b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"Replace me by any text you'd like.\"\n",
    "# encoded_input = tokenizer(text, return_tensors='pt')\n",
    "# output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91f15bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7196db1d",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd496749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted', zero_division=0)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    metrics = {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "    if wandb.run is not None:\n",
    "        wandb.log({\"eval_\" + k: v for k, v in metrics.items()})\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e656f1d5",
   "metadata": {},
   "source": [
    "# Running..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55545ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vibrant-microwave-11</strong> at: <a href='https://wandb.ai/bsindala-university-of-alabama-at-birmigham/llm-anomaly-detection/runs/n6bgduck' target=\"_blank\">https://wandb.ai/bsindala-university-of-alabama-at-birmigham/llm-anomaly-detection/runs/n6bgduck</a><br> View project at: <a href='https://wandb.ai/bsindala-university-of-alabama-at-birmigham/llm-anomaly-detection' target=\"_blank\">https://wandb.ai/bsindala-university-of-alabama-at-birmigham/llm-anomaly-detection</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250902_134728-n6bgduck/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for wandb.init()..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/user/bsindala/PhD/Research/LLM_Anomaly_Detection/wandb/run-20250902_135215-agjyvndl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/bsindala-university-of-alabama-at-birmigham/llm-anomaly-detection/runs/agjyvndl' target=\"_blank\">hopeful-wind-12</a></strong> to <a href='https://wandb.ai/bsindala-university-of-alabama-at-birmigham/llm-anomaly-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/bsindala-university-of-alabama-at-birmigham/llm-anomaly-detection' target=\"_blank\">https://wandb.ai/bsindala-university-of-alabama-at-birmigham/llm-anomaly-detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/bsindala-university-of-alabama-at-birmigham/llm-anomaly-detection/runs/agjyvndl' target=\"_blank\">https://wandb.ai/bsindala-university-of-alabama-at-birmigham/llm-anomaly-detection/runs/agjyvndl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:W&B initialized for project: llm-anomaly-detection\n",
      "INFO:__main__:Loading tokenizer for roberta-base...\n",
      "INFO:__main__:Loading and preprocessing data from /data/user/bsindala/PhD/Research/DataSets/CICIoMT2024/WiFI and MQTT/attacks/CSV/...\n",
      "INFO:__main__:Loading and preparing datasets for 2-class configuration...\n",
      "INFO:__main__:Loading datasets with streaming...\n",
      "INFO:__main__:Processing train data...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        # Intialization of WANDB\n",
    "        wandb.login(key=WANDB_API_KEY)\n",
    "        wandb.init(\n",
    "            entity =WANDB_ENTITY,\n",
    "            project=WANDB_PROJECT, \n",
    "            config={\n",
    "                \"model_name\": MODEL_NAME,\n",
    "                \"num_epochs\": NUM_EPOCHS,\n",
    "                \"batch_size\": BATCH_SIZE,\n",
    "                \"learning_rate\": LEARNING_RATE,\n",
    "                \"max_seq_length\": MAX_SEQ_LENGTH,\n",
    "                \"class_config\": CLASS_CONFIG,\n",
    "                \"sample_frac\": SAMPLE_FRAC\n",
    "            }\n",
    "        )\n",
    "        logger.info(f'W&B initialized for project: {WANDB_PROJECT}')\n",
    "        \n",
    "         # Initialization of tokenizer\n",
    "        logger.info(f\"Loading tokenizer for {MODEL_NAME}...\")\n",
    "        tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "    \n",
    "        # Loading data\n",
    "        logger.info(f\"Loading and preprocessing data from {DATA_DIR}...\")\n",
    "        train_ds, val_ds, test_ds, label_encoder, class_weights, feature_names = load_and_prepare(\n",
    "            data_dir=DATA_DIR,\n",
    "            class_config=CLASS_CONFIG,\n",
    "            tokenizer=tokenizer,\n",
    "            max_seq_len=MAX_SEQ_LENGTH,\n",
    "            random_state=RANDOM_STATE,\n",
    "            sample_frac=SAMPLE_FRAC\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Sample textualized data:\")\n",
    "        for i in range(min(3, len(train_ds))):\n",
    "            logger.info(f\"Text: {train_ds['text'][i]}\")\n",
    "            logger.info(f\"Label: {label_encoder.inverse_transform([train_ds['label'][i]])[0]}\")\n",
    "        \n",
    "        if wandb.run is not None:\n",
    "            wandb.log({\n",
    "                'training_size': len(train_ds),\n",
    "                'val_size': len(val_ds),\n",
    "                'test_size': len(test_ds),\n",
    "                'num_classes': len(label_encoder.classes_),\n",
    "                'features_used': len(feature_names)\n",
    "            })\n",
    "    \n",
    "        num_labels = len(label_encoder.classes_)\n",
    "        id2label = {i: label for i, label in enumerate(label_encoder.classes_)}\n",
    "        label2id = {label: i for i, label in enumerate(label_encoder.classes_)}\n",
    "    \n",
    "        logger.info(f\"Number of labels: {num_labels}, Classes: {list(label_encoder.classes_)}, Test size: {len(test_ds)}\")\n",
    "        if wandb.run is not None:\n",
    "            wandb.log({'classes': list(label_encoder.classes_)})\n",
    "        \n",
    "        # Validate class config\n",
    "        expected_classes = {2: 2, 6: 6, 19: 19}.get(CLASS_CONFIG)\n",
    "        if num_labels != expected_classes:\n",
    "            raise ValueError(f\"Expected {expected_classes} classes, but found {num_labels}.\")\n",
    "        \n",
    "        logger.info('\\nScript execution completed successfully!')\n",
    "    except Exception as e:\n",
    "        logger.info(f'Error: An exception occured during execution: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362a9154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:.conda-anomalyenv_v310]",
   "language": "python",
   "name": "conda-env-.conda-anomalyenv_v310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
